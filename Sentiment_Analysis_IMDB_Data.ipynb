{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN3M0n1/froSQAB/RjbvMD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-MODxzKK_nnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis"
      ],
      "metadata": {
        "id": "7kZgeh0H_pcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Embedding Layer\n"
      ],
      "metadata": {
        "id": "gjHfO8RH_zfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "S2I0rBJK_1jW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDB dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)"
      ],
      "metadata": {
        "id": "mh4ksrz9AOdy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMDB reviews have different lengths, but Dense expects a fixed number of neurons\n",
        "# We are ensuring every input is exactly 200 words."
      ],
      "metadata": {
        "id": "HI_LLrkqAeNe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to ensure fixed-length inputs\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)\n"
      ],
      "metadata": {
        "id": "tuxNPE-sA3N4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model using only Dense layers\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(200,)),  # Convert 2D sequences to 1D\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])"
      ],
      "metadata": {
        "id": "csmiDML2BZz8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "q12gf6g9IYb0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVE8HnoxIqNc",
        "outputId": "cd6cf3e7-0f02-443d-a7b6-fd8a528c7079"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5044 - loss: 0.6916\n",
            "Epoch 2/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5021 - loss: 0.6913\n",
            "Epoch 3/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5021 - loss: 0.6906\n",
            "Epoch 4/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5073 - loss: 0.6904\n",
            "Epoch 5/5\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5005 - loss: 0.6902\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78ed46d1cfe0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BScsLb14JBaP",
        "outputId": "563a6ced-ab6c-43ac-f0cf-9d794483a035"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4930 - loss: 0.7020\n",
            "Test Accuracy: 50.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on the first test sample\n",
        "predicted_sentiment = model.predict(x_test[0:1])\n",
        "print(\"Predicted Sentiment:\", \"Positive\" if predicted_sentiment[0][0] > 0.5 else \"Negative\")\n",
        "# x_test[0:1] as Keras models expect input in batches, i.e., a 2D array: (batch_size, sequence_length) -> x_test[0:1] = (1,200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLizFCvNNBO-",
        "outputId": "fd3623dd-b5bc-4f0e-92e5-19589fee7d65"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Predicted Sentiment: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWLltkCvNbKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Embedding Layer"
      ],
      "metadata": {
        "id": "CA_NywuMOw05"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uI6PCPxNPiAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Embedding layer **transforms integer word indices into dense vector representations.**\n",
        "\n",
        "***Example:***\n",
        "Original Sentence:\n",
        "\"The movie was amazing, I loved it!\"\n",
        "Tokenized & Indexed Representation:\n",
        "[10, 482, 21, 345, 7, 99, 4]\n",
        "\n",
        "***What Embedding Does***\n",
        "Instead of treating 10, 482, 21, etc., as just numbers, an embedding layer converts each of them into a dense vector of real numbers.\n",
        "\n",
        "For example, the word index 10 (which represents \"The\") might be mapped to:\n",
        "[0.12, -0.25, 0.78, ..., 0.05]  # A 128-dimensional vector\n",
        "Each word in the sentence gets a similar vector.\n",
        "\n",
        "***Why Is This Useful?***\n",
        "Captures Word Meaning → Similar words will have similar vectors.\n",
        "Avoids Numeric Misinterpretation → Without embeddings, the model might think 99 > 10, which makes no sense for words.\n",
        "Enables Word Relationships → Words like \"king\" and \"queen\" will have similar embeddings.\n",
        "\n",
        "***Example: Before vs After Embedding***\n",
        "Before Embedding (Word Indices)\n",
        "\n",
        "[10, 482, 21, 345, 7, 99, 4]  # Just numbers\n",
        "After Embedding (Word Vectors, Each of Size 128)\n",
        "\n",
        "[\n",
        "  [0.12, -0.25, 0.78, ..., 0.05],   # Word 10\n",
        "  [0.34, 0.67, -0.12, ..., -0.89],  # Word 482\n",
        "  [0.08, 0.15, -0.32, ..., 0.40],   # Word 21\n",
        "  ...\n",
        "]\n",
        "Each word now has a dense vector representation that captures its meaning."
      ],
      "metadata": {
        "id": "igkkM1iyPjHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "tScpiu_7P9h5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=10000)\n",
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s46Vtn5SRHoP",
        "outputId": "6063f250-6ee2-492d-f4ed-6bb251265a7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to ensure fixed-length inputs\n",
        "x_train = pad_sequences(x_train, maxlen=200)\n",
        "x_test = pad_sequences(x_test, maxlen=200)"
      ],
      "metadata": {
        "id": "Y6XeDbLYTr8i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build models using only Dense layers with an Embedding layer\n",
        "model = models.Sequential([\n",
        "    layers.Embedding(input_dim=10000, output_dim=128, input_length=200), # Converts word indices to vectors\n",
        "    layers.Flatten(), # Flatten embeddings into a 1D vector\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64,activation='relu'),\n",
        "    layers.Dense(1,activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "KauBJLezUBYw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "w6rHK6wS4g-P"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kV-s4W85AUv",
        "outputId": "2416366c-dbac-4d2d-a3f8-25ece434b0f9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 390ms/step - accuracy: 0.5926 - loss: 0.6453\n",
            "Epoch 2/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 365ms/step - accuracy: 0.9278 - loss: 0.1841\n",
            "Epoch 3/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 393ms/step - accuracy: 0.9912 - loss: 0.0380\n",
            "Epoch 4/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 368ms/step - accuracy: 0.9987 - loss: 0.0072\n",
            "Epoch 5/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 393ms/step - accuracy: 0.9998 - loss: 0.0019\n",
            "Epoch 6/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 364ms/step - accuracy: 1.0000 - loss: 3.5102e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 387ms/step - accuracy: 1.0000 - loss: 2.0582e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 365ms/step - accuracy: 1.0000 - loss: 1.2618e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 390ms/step - accuracy: 1.0000 - loss: 9.7026e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 6.6401e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7bdd5280f620>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy:{test_accuracy * 100:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys0fWlqm5JdK",
        "outputId": "2553c0e2-be71-49ed-dbe5-879cc73aa2f3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8498 - loss: 0.6821\n",
            "Test accuracy:84.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on the first test sample\n",
        "predicted_sentiment = model.predict(x_test[0:1])\n",
        "print(\"Predicted Sentiment:\", \"Positive\" if predicted_sentiment[0][0] > 0.5 else \"Negative\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw3aTfWi60JJ",
        "outputId": "650c47b6-7504-4a7b-c1a4-f96b40b683c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
            "Predicted Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KtgRxpgU7QZ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}